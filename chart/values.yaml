## @section Global parameters
## Global parameters
## Please, note that this will override parameters, including dependencies, configured to use the global value
## Current available global parameters: imageRegistry, imagePullSecrets and storageClass

global:
  imageRegistry: ""
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  storageClass: ""

## @section Common parameters
##

## @param nameOverride String to partially override common.names.fullname template (will maintain the release name); use for setting web hostname
##
nameOverride: ""
## @param fullnameOverride String to fully override common.names.fullname template
##
fullnameOverride: ""
## @param clusterDomain Kubernetes cluster domain
##
clusterDomain: cluster.local
## @param extraDeploy Array of extra objects to deploy with the release (evaluated as a template)
##
extraDeploy: []
## @param commonLabels Add labels to all the deployed resources
##
commonLabels: {}
## @param commonAnnotations Add annotations to all the deployed resources
##
commonAnnotations: {}

## Enable diagnostic mode throughout the application
##
diagnosticMode:
  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
  ##
  enabled: false
  ## @param diagnosticMode.command Command to override all containers in the deployment
  ##
  command:
    - sleep
  ## @param diagnosticMode.args Args to override all containers in the deployment
  ##
  args:
    - infinity

# @param external DNS subdomain; used to build sub-components FQDNs and configure web CORS (if enabled)
##
externalDomain: "" #"dev.advana.boozallencsn.com"
ingress:
  enabled: true
  ## @param ingress.controller The ingress controller type. Currently supports `default`, `gce` and `ncp`
  ## leave as `default` for most ingress controllers.
  ## set to `gce` if using the GCE ingress controller
  ## set to `ncp` if using the NCP (NSX-T Container Plugin) ingress controller
  ##
  controller: default
  ingressClassName: ""
  ml:
    enabled: true
    hostname: ml.gamechanger
    ## @param ingress.ml.pathType Ingress path type
    ##
    pathType: ImplementationSpecific
    ## @param ingress.ml.annotations [object] Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
    ## Use this parameter to set the required annotations for cert-manager, see
    ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
    ## e.g:
    ## annotations:
    ##   kubernetes.io/ingress.class: nginx
    ##   cert-manager.io/cluster-issuer: cluster-issuer-name
    ##
    annotations:
      {}
      # ingress.kubernetes.io/ssl-redirect: "true"
      # ingress.kubernetes.io/proxy-body-size: "0"
      # nginx.ingress.kubernetes.io/ssl-redirect: "true"
      # nginx.ingress.kubernetes.io/proxy-body-size: "0"
    tls: true
    ## @param ingress.ml.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
    ##
    selfSigned: true
    ## @param ingress.ml.extraHosts An array with additional hostname(s) to be covered with the ingress record
    ## e.g:
    ## extraHosts:
    ##   - name: ml.gamechanger.domain
    ##     path: /
    ##
    extraHosts: []
    ## @param ingress.ml.secrets Custom TLS certificates as secrets
    ## NOTE: 'key' and 'certificate' are expected in PEM format
    ## NOTE: 'name' should line up with a 'secretName' set further up
    ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
    ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ## e.g:
    ## secrets:
    ##   - name: ml.gamechanger.domain-tls
    ##     key: |-
    ##       -----BEGIN RSA PRIVATE KEY-----
    ##       ...
    ##       -----END RSA PRIVATE KEY-----
    ##     certificate: |-
    ##       -----BEGIN CERTIFICATE-----
    ##       ...
    ##       -----END CERTIFICATE-----
    ##
    secrets: []
  web:
    enabled: true
    hostname: gamechanger
    ## @param ingress.web.pathType Ingress path type
    ##
    pathType: ImplementationSpecific
    ## @param ingress.web.annotations [object] Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
    ## Use this parameter to set the required annotations for cert-manager, see
    ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
    ## e.g:
    ## annotations:
    ##   kubernetes.io/ingress.class: nginx
    ##   cert-manager.io/cluster-issuer: cluster-issuer-name
    ##
    annotations:
      ingress.kubernetes.io/ssl-redirect: "true"
      ingress.kubernetes.io/proxy-body-size: "0"
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
    tls: true
    ## @param ingress.web.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
    ##
    selfSigned: true
    ## @param ingress.web.extraHosts An array with additional hostname(s) to be covered with the ingress record
    ## e.g:
    ## extraHosts:
    ##   - name: web.gamechanger.domain
    ##     path: /
    ##
    extraHosts: []
    ## @param ingress.web.secrets Custom TLS certificates as secrets
    ## NOTE: 'key' and 'certificate' are expected in PEM format
    ## NOTE: 'name' should line up with a 'secretName' set further up
    ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
    ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ## e.g:
    ## secrets:
    ##   - name: web.gamechanger.domain-tls
    ##     key: |-
    ##       -----BEGIN RSA PRIVATE KEY-----
    ##       ...
    ##       -----END RSA PRIVATE KEY-----
    ##     certificate: |-
    ##       -----BEGIN CERTIFICATE-----
    ##       ...
    ##       -----END CERTIFICATE-----
    ##
    secrets: []

ml:
  # image - <Object>
  #   Main app image details - also used to run all jobs defined in .Values
  image:
    registry: ""
    repository: "advana/gamechanger/gamechanger-ml"
    pullPolicy: Always
    tag: "latest"
    ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    enabled: true
    mountPath: "/opt/app-root/volume"
    ## A manually managed Persistent Volume and Claim
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    existingClaim: ""

    ## ml Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    ## Storage class of PV to bind. By default it looks for standard storage class.
    ## If the PV uses a different storage class, specify that here.
    storageClass: ""
    accessModes:
      - ReadWriteOnce
    size: 500Gi
  # replicaCount - <Integer >= 1>
  #   Number of app pod replicas to launch in the load-balancing group.
  #
  #   Tips:
  #   - when troubleshooting, set to 1 to avoid dealing with complications of load-balanced traffic
  replicaCount: 1

  existingConfigMap: ""

  updateStrategy:
    type: RollingUpdate

  # startCommand - <Array of strings>
  #   Entrypoint/command to be executed by the main application pod.
  #   Will completely override any entrypoint/cmd baked into the container.
  #
  #   Tips:
  #     - when troubleshooting, set to ["sleep", "infinity"] then exec into container and tweak/relaunch app as necessary
  startCommand:
    - "/bin/bash"
    - "./gamechangerml/api/fastapi/startFast.sh"
  init:
    # runs every time ml container is restarted
    container:
      enabled: true
      image:
        registry: ""
        repository: "advana/gamechanger/gamechanger-ml"
        tag: "latest"
      script: |
        echo test
    # runs once per chart release as a k8s job
    job:
      enabled: true
      image:
        registry: ""
        repository: "advana/gamechanger/gamechanger-ml"
        tag: "latest"
      script: |
        echo test

  # probes - <Object>
  #   Probes for determining pod/container health, as per ...
  #   https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
  #
  #   Tips:
  #     - if troubleshooting, set to empty object {}; to avoid k8s restarting container and blocking traffic to it
  probes: {}

  # podAnnotations - <Object>  additional pod annotations
  podAnnotations:
    iam.amazonaws.com/role: advana/k8s/s3.wildcard

  # service - <Object/Map>
  #   Port details of the service used to open application pod to connections from outside.
  #   Note: must be of type NodePort and only http/https keys are supported.
  #   For syntax, refer to service.spec.ports[*] definitions of the NodePort service https://kubernetes.io/docs/concepts/services-networking/service/#nodeport
  service:
    type: NodePort # ClusterIP
    ports:
      http: 5000
      https: 443
    nodePorts:
      http: 31009
      https: 31209
    extraPorts:
      []
      # - port: 443
      #   targetPort: 8443
      #   nodePort: 31209
      #   protocol: TCP
      #   name: https
  # podTolerations - <Array[Map[string, string]]>
  #   Pod tolerations. Used to make sure pod runs on nodes that are specifically tainted to prevent other pods from
  #   scheduling there by default. Reference https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
  podTolerations:
    - key: "HighMemory"
      operator: "Equal"
      effect: "NoExecute"
      value: "true"

  # podSecurityContext - <Object>
  #   Sets security context for main application and job pods.
  #   This primarily comes into play when mounting files and volumes, but has other uses.
  #   For more on what goes in here, reference https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  podSecurityContext:
    fsGroup: 1001
    fsGroupChangePolicy: "OnRootMismatch"

  # containerSecurityContext - <Map>
  #   Security context for app and job containers.
  #   It's useful to define this to match user-id and group-id of the application and its' files inside container
  #   For more on what goes in here, reference https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  containerSecurityContext:
    runAsUser: 1001
    runAsGroup: 1001

  # serviceAccount - <Map>
  #   Config of service account to be used by the app and job pods
  #   Service account determines what permissions pods/resources have when they interact with other k8s resources & API's
  serviceAccount:
    # create - <bool> - whether to attempt creating the service account
    create: true
    # name - <string> - override with custom name. useful if there is a pre-existing service account you should be using
    name: ""

  # resources - <Map>
  #   Defines minimum and maximum cpu/memory requirements for each application pod (except one-time-job pods)
  #   For more on what goes in here, reference https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  resources:
    requests:
      memory: "20Gi"
      cpu: "4"

  # extraEnvVars - An array to add extra environment variables
  extraEnvVars: []
  # extraEnvVarsSecret - existing Secret with extra environment variables
  extraEnvVarsSecret: ""
  # extraEnvVarsCM - existing ConfigMap with extra environment variables
  extraEnvVarsCM: ""

  tls:
    enabled: true
    # auto-generate tls bundle completely
    autoGenerated: true
    # provide an existing secret with {tls.key, ca.crt, tls.crt} keys defined
    existingSecret: ""
    # where tls files should be mounted (either auto generated or provided as files)
    mountPath: "/opt/app-root/src/secrets"
    # if no existing secret, these should be set and mounted
    # Certificate file on ML container(s)
    certFilename: "tls.crt"
    # Path to cert's key file on ML container(s)
    certKeyFilename: "tls.key"
    # Path to CA certificate file on ML container(s)
    certCAFilename: "ca.crt"

web:
  image:
    registry: ""
    repository: "advana/gamechanger/gamechanger-web"
    tag: "latest"

  replicaCount: 1

  startCommand: []

  init:
    # runs every time web container is restarted
    container:
      enabled: true
      image:
        registry: ""
        repository: "advana/gamechanger/gamechanger-web"
        tag: "latest"
      script: |
        echo hi
    # runs once per chart release as a k8s job
    job:
      enabled: true
      image:
        registry: ""
        repository: "advana/gamechanger/gamechanger-web"
        tag: "latest"
      script: |
        _urlenc_pass=$(2>/dev/null node -e "console.log(encodeURIComponent(process.env.POSTGRES_PASSWORD_GAME_CHANGER))")
        sequelize db:migrate \
          --options-path ./.sequelize-game_changer \
          --env game_changer \
          --url "postgresql://${POSTGRES_USER_GAME_CHANGER}:${_urlenc_pass}@${POSTGRES_HOST_GAME_CHANGER}/game_changer"
        _urlenc_pass=$(2>/dev/null node -e "console.log(encodeURIComponent(process.env.POSTGRES_PASSWORD_GC_ORCHESTRATION))")
        sequelize db:migrate \
          --options-path ./.sequelize-gc-orchestration \
          --env gc_orchestration \
          --url "postgresql://${POSTGRES_USER_GC_ORCHESTRATION}:${_urlenc_pass}@${POSTGRES_HOST_GC_ORCHESTRATION}/gc-orchestration"
  # containerSecurityContext - <Map>
  #   Security context for app and job containers.
  #   It's useful to define this to match user-id and group-id of the application and its' files inside container
  #   For more on what goes in here, reference https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  containerSecurityContext:
    runAsUser: 1001
    runAsGroup: 1001
  qlik:
    sysAccount: ""
    adDomain: ""
  # service - <Object/Map>
  #   Port details of the service used to open application pod to connections from outside.
  #   Note: must be of type NodePort and only http/https keys are supported.
  #   For syntax, refer to service.spec.ports[*] definitions of the NodePort service https://kubernetes.io/docs/concepts/services-networking/service/#nodeport
  service:
    type: NodePort # ClusterIP
    ports:
      http: 80
      https: 8443
    nodePorts:
      http: 31007
      https: 31207
    extraPorts:
      []
      # - port: 443
      #   targetPort: 8443
      #   nodePort: 31209
      #   protocol: TCP
      #   name: https

  tls:
    enabled: true
    # auto-generate tls bundle completely
    autoGenerated: true
    # provide an existing secret with {tls.key, ca.crt, tls.crt} keys defined
    existingSecret: ""
    mountPath: "/opt/app-root/src/secrets"
    # if no existing secret, these should be set and mounted
    # Certificate file
    certFilename: "tls.crt"
    # Path to cert's key file
    certKeyFilename: "tls.key"
    # Path to CA certificate file
    certCAFilename: "ca.crt"
    #
    dhParamsFileName: ""

  # extraEnvVars - An array to add extra environment variables
  extraEnvVars:
    # should be static (ie not generated w/ templating)
    - name: PULL_NODES_FROM_NEO4J_MAX_LIMIT
      value: "500"
    - name: GRAPH_VIEW_NODES_DISPLAYED_WARNING_LIMIT
      value: "500"
    - name: MAX_GRAPH_VIEW_NODES_DISPLAYED
      value: "5000"
    - name: REACT_APP_COOKIE_DOMAIN
      value: "dev.advana.boozallencsn.com"
    - name: CDO_ELASTICSEARCH_INDEX
      value: gc-cdo
    - name: EDA_ELASTICSEARCH_INDEX
      value: gc_eda_2021_json
    - name: HERMES_ELASTICSEARCH_INDEX
      value: hermes_test_1
    - name: EMAIL_ADDRESS
      value: 607749@bah.com
    - name: EMAIL_TRANSPORT_HOST
      value: "10.224.0.248"
    - name: EMAIL_TRANSPORT_PORT
      value: "25"
    - name: DOCKER
      value: "true"
    - name: S3_REGION
      value: us-east-1
    - name: PG_UM_DB
      value: uot
    - name: PG_LOGGING
      value: "false"
    - name: JIRA_ADVANA_PRODUCT
      value: customfield_12719
    - name: SECURE_SESSION
      value: "false"
    - name: DISABLE_SSO
      value: "true"
    - name: SERVICE_ACCOUNT_PHONE
      value: 202-555-0134
    - name: SERVICE_ACCOUNT_ORG
      value: OSD
    - name: SERVICE_ACCOUNT_ENV
      value: NIPR
    - name: DISABLE_FRONT_END_CONFIG
      value: "false"
    - name: REACT_APP_GC_DECOUPLED
      value: "true"
    - name: REACT_APP_ROOT_CLONE
      value: gamechanger
    - name: REACT_APP_NODE_ENV
      value: development
    - name: REACT_APP_GLUU_SSO
      value: disabled
    - name: GAMECHANGER_ELASTICSEARCH_INDEX
      value: gamechanger
    - name: GAMECHANGER_ELASTICSEARCH_SUGGEST_INDEX
      value: gamechanger
    - name: GAMECHANGER_ELASTICSEARCH_ENTITIES_INDEX
      value: entities
    - name: GAMECHANGER_ELASTICSEARCH_HISTORY_INDEX
      value: search_history
    - name: REACT_APP_QLIK_URL
      value: https://qlik.audit.boozallencsn.com
    - name: REACT_APP_MEGA_MENU_BASE_DOMAIN
      value: http://app.dev.advana.boozallencsn.com
    - name: COOKIE_DOMAIN
      value: .boozallencsn.com
    - name: QLIK_URL
      value: https://10.194.9.96:4242
    - name: QLIK_WS_URL
      value: wss://EC2AMAZ-53VQBQF.drced.local:4747
    - name: SAML_ENTRYPOINT
      value: https://sso.advana.boozallencsn.com:8443/auth/realms/local-uot-test/protocol/saml
    - name: REACT_APP_CLASSIFICATION_BANNER
      value: COMBINED DEV
    - name: REACT_APP_CLASSIFICATION_BANNER_COLOR
      value: GREEN
    - name: EXPRESS_TRUST_PROXY
      value: "true"
    - name: REACT_APP_JEXNET_LINK
      value: https://jexnet.dev.advana.boozallencsn.com/
    - name: DATA_CATALOG_HOST
      value: "10.194.9.123"
    - name: DATA_CATALOG_PORT
      value: "8443"
    - name: REACT_APP_SUPPORT_HREF
      value: https://support.advana.data.mil/plugins/servlet/desk/portal/5/create/113
    - name: REACT_APP_WIKI_HREF
      value: http://wiki.advana.data.mil
    - name: REACT_APP_TUTORIAL_HREF
      value: http://10.194.9.109:8080
    - name: REACT_APP_DATA_CATALOG_LINK
      value: http://10.194.9.123:8443
    # can be templated
    - name: EDA_ELASTICSEARCH_PROTOCOL
      value: https
    - name: EDA_DATA_HOST
      value: 10.194.9.105
    - name: MYSQL_HOST_MATOMO
      value: 10.194.9.69
    - name: REACT_APP_MATOMO_LINK
      value: http://10.194.9.69
    - name: APPROVED_API_CALLERS
      value: >
        http://localhost:8080 http://localhost:3000 http://localhost:8080 http://localhost:8001 http://localhost:8990 http://localhost:3000 http://192.168.56.101:3000 http://10.194.9.104 http://10.194.9.122 http://10.194.9.70 http://10.194.9.81 http://10.194.9.90 http://10.194.9.100 http://10.194.9.101 http://10.194.9.102 http://10.194.9.105 http://10.194.9.109 http://10.194.9.102 http://10.194.9.110 http://10.194.9.122 http://10.194.9.114 http://10.194.9.86 http://audit.bah.com http://dev.audit.boozallencsn.com https://dev.audit.boozallencsn.com https://audit.boozallencsn.com
  # extraEnvVarsSecret - existing Secret with extra environment variables
  extraEnvVarsSecret: ""
  # extraEnvVarsCM - existing ConfigMap with extra environment variables
  extraEnvVarsCM: ""
  # podTolerations - <Array[Map[string, string]]>
  #   Pod tolerations. Used to make sure pod runs on nodes that are specifically tainted to prevent other pods from
  #   scheduling there by default. Reference https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
  podTolerations:
    - key: "HighMemory"
      operator: "Equal"
      effect: "NoExecute"
      value: "true"

pipelines:
  image:
    registry: ""
    repository: "gc-data-pipelines"
    tag: "latest"

crawlers:
  # replicaCount - <Integer >= 1>
  #   Number of app pod replicas to launch in the load-balancing group.
  #
  #   Tips:
  #   - when troubleshooting, set to 1 to avoid dealing with complications of load-balanced traffic
  replicaCount: 1
  persistentVolumeClaims:
    downloads:
      # Enable persistent volume for storing crawler downloads
      enabled: false
      # Volume size for downloads
      size: 1Gi
      # If using a custom storageClass, pass name here
      storageClassName:
      # access mode of the persistent volume
      accessMode: ReadWriteOnce
      ## optional subpath for dag volume mount
      subPath: ~

  # Airflow crawler configs
  images:
    crawler:
      registry: ""
      repository: "gc-crawler-downloader-test"
      tag: "latest"
    scanner:
      registry: ""
      repository: "gc-crawler-downloader-test"
      tag: "latest"
    busybox:
      registry: ""
      repository: "docker/busybox"
      tag: "latest"

  configVars:
    scanConcurrency: ""
    awsConnID: ""
    localCrawlerOutputLocation: ""
    localCrawlerDownloadDirectory: ""
    localPreviousManifestLocation: ""
    # remove? default must be 'y' if running via airflow, since there will be no user input
    crawlerSkipConfirmation: ""

    downloadManifestBucket: ""
    downloadManifestKey: ""
    downloadManifestCacertPath: ""

    # remove? should be same as localPreviousManifestLocation
    downloadManifestLocalDestination: ""

    scanUploadBucket: ""
    scanDeleteAfterUpload: ""
    scanS3Dir: ""
    scanSkipS3Upload: ""

    uploadManifestBucket: ""
    uploadManifestKey: ""
    uploadManifestCacertPath: ""
    uploadManifestFilepath: ""

  configFiles:
    cacert.pem: |-

    monday.txt: |-

    tuesday.txt: |-

    wednesday.txt: |-

    thursday.txt: |-

    friday.txt: |-

    saturday.txt: |-

    sunday.txt: |-

  ## @param crawlers.existingSecret Permits specifying a secret name for crawler configuration. Should include {}
  existingSecret: ""

neo4j:
  asSubchart: true
  hosts: []
  port: ""
  auth:
    existingSecret: ""
    password: ""

  version: "4.4.5"
  nameOverride: ""
  replicaCount: 1
  podAntiAffinity: true
  acceptLicenseAgreement: "yes"

  image:
    registry: ""
    repository: "neo4j"
    tag: "4.4.5"
  service:
    type: ClusterIP
    ports:
      http: 7474
      https: 7473
      bolt: 7687
      backup: 6362
      jmx: 3637
      graphite: 2003
      prometheus: 2004
      discovery: 5000
      tx: 6000
      raft: 7000
      boltrouting: 7688
    nodePorts:
      http: ""
      https: ""
    extraPorts: []
  # set resources for the Neo4j Container. The values set will be used for both "requests" and "limit".
  resources:
    cpu: "1000m"
    memory: "2Gi"
  # initContainers for the Neo4j pod
  initContainers: []
  # Neo4j Configuration (yaml format)
  config:
    dbms.config.strict_validation: "true"

    # The amount of memory to use for mapping the store files.
    # The default page cache memory assumes the machine is dedicated to running
    # Neo4j, and is heuristically set to 50% of RAM minus the Java heap size.
    #dbms.memory.pagecache.size: "74m"

    #The number of Cypher query execution plans that are cached.
    #dbms.query_cache_size: "10"

    # Java Heap Size: by default the Java heap size is dynamically calculated based
    # on available system resources. Uncomment these lines to set specific initial
    # and maximum heap size.
    #dbms.memory.heap.initial_size: "317m"
    #dbms.memory.heap.max_size: "317m"

  # securityContext defines privilege and access control settings for a Pod or Container. Making sure that we dont run Neo4j as root user.
  securityContext:
    runAsNonRoot: true
    runAsUser: 7474
    runAsGroup: 7474
    fsGroup: 7474
    fsGroupChangePolicy: "Always"

  # Readiness probes are set to know when a container is ready to be used.
  # Because Neo4j uses Java these values are large to distinguish between long Garbage Collection pauses (which don't require a restart) and an actual failure.
  # These values should mark Neo4j as not ready after at most 5 minutes of problems (20 attempts * max 15 seconds between probes)
  readinessProbe:
    failureThreshold: 20
    timeoutSeconds: 10
    periodSeconds: 5

  # Liveness probes are set to know when to restart a container.
  # Because Neo4j uses Java these values are large to distinguish between long Garbage Collection pauses (which don't require a restart) and an actual failure.
  # These values should trigger a restart after at most 10 minutes of problems (40 attempts * max 15 seconds between probes)
  livenessProbe:
    failureThreshold: 40
    timeoutSeconds: 10
    periodSeconds: 5

  # Startup probes are used to know when a container application has started.
  # If such a probe is configured, it disables liveness and readiness checks until it succeeds
  # When restoring Neo4j from a backup it's important that startup probe gives time for Neo4j to recover and/or upgrade store files
  # When using Neo4j clusters it's important that startup probe give the Neo4j cluster time to form
  startupProbe:
    failureThreshold: 1000
    periodSeconds: 5

  # top level setting called ssl to match the "ssl" from "dbms.ssl.policy"
  tls:
    enabled: true
    # auto-generate tls bundle completely
    autoGenerated: true
    # provide an existing secret with {tls.key, ca.crt, tls.crt} keys defined
    existingSecret: ""
    # if no existing secret, these should be set and mounted
    # Certificate file on neo4j container(s)
    certFilename: "tls.crt"
    # Path to cert's key file on neo4j container(s)
    certKeyFilename: "tls.key"
    # Path to CA certificate file on neo4j container(s)
    certCAFilename: "ca.crt"

  volumes:
    data:
      # REQUIRED: specify a volume mode to use for data
      # Valid values are share|selector|defaultStorageClass|volume|volumeClaimTemplate|dynamic
      # To get up-and-running quickly, for development or testing, use "defaultStorageClass" for a dynamically provisioned volume of the default storage class.
      mode: "defaultStorageClass"
      # Only used if mode is set to "defaultStorageClass"
      # Dynamic provisioning using the default storageClass
      defaultStorageClass:
        accessModes:
          - ReadWriteOnce
        requests:
          storage: 10Gi
    # provide a volume to use for backups
    # n.b. backups will be written to /backups on the volume
    # any of the volume modes shown above for data can be used for backups
    backups:
      mode: "defaultStorageClass"
      # Only used if mode is set to "defaultStorageClass"
      # Dynamic provisioning using the default storageClass
      defaultStorageClass:
        accessModes:
          - ReadWriteOnce
        requests:
          storage: 10Gi

    # provide a volume to use for logs
    # n.b. logs will be written to /logs/$(POD_NAME) on the volume
    # any of the volume modes shown above for data can be used for logs
    logs:
      mode: "defaultStorageClass"
      # Only used if mode is set to "defaultStorageClass"
      # Dynamic provisioning using the default storageClass
      defaultStorageClass:
        accessModes:
          - ReadWriteOnce
        requests:
          storage: 2Gi

    # provide a volume to use for csv metrics (csv metrics are only available in Neo4j Enterprise Edition)
    # n.b. metrics will be written to /metrics/$(POD_NAME) on the volume
    # any of the volume modes shown above for data can be used for metrics
    metrics:
      mode: "defaultStorageClass"
      # Only used if mode is set to "defaultStorageClass"
      # Dynamic provisioning using the default storageClass
      defaultStorageClass:
        accessModes:
          - ReadWriteOnce
        requests:
          storage: 2Gi

    # provide a volume to use for import storage
    # n.b. import will be mounted to /import on the underlying volume
    # any of the volume modes shown above for data can be used for import
    import:
      mode: "defaultStorageClass"
      # Only used if mode is set to "defaultStorageClass"
      # Dynamic provisioning using the default storageClass
      defaultStorageClass:
        accessModes:
          - ReadWriteOnce
        requests:
          storage: 10Gi

    # provide a volume to use for licenses
    # n.b. licenses will be mounted to /licenses on the underlying volume
    # any of the volume modes shown above for data can be used for licenses
    licenses:
      mode: "share" # share an existing volume (e.g. the data volume)
      share:
        name: "data"
##########################################
# External/dependency charts #
##########################################
elasticsearch:
  asSubchart: true
  name: gamechanger
  hosts: []
  port: ""
  image:
    registry: ""
    repository: bitnami/elasticsearch
    tag: 7.17.2-debian-10-r4
  extraConfig: {}
  ingress:
    enabled: false
  security:
    enabled: true
    fipsMode: true
    existingSecret: ""
    tls:
      autoGenerated: true
      # if not autogenerated, or not using subchart, set this to the filename in ./certs/ with the elasticearch CA pem
      certCAFilename: "ca.crt"

  master:
    replicas: 3
    podSecurityContext:
      enabled: true
  coordinating:
    replicas: 1
    podSecurityContext:
      enabled: true
  data:
    replicas: 1
    persistence:
      size: 20Gi
    podSecurityContext:
      enabled: true

## @section PostgreSQL Parameters

## PostgreSQL chart configuration
## ref: https://github.com/bitnami/charts/blob/master/bitnami/postgresql/values.yaml
## @param postgresql.enabled If external database is used, set it to `false`
## @param postgresql.nameOverride String to partially override common.names.fullname template with a string (will prepend the release name)
## @param postgresql.postgresqlUsername Postgresql username
## @param postgresql.postgresqlPassword Postgresql password
## @param postgresql.existingSecret Set Postgresql password via an existing secret
## @param postgresql.postgresqlExtendedConf [object] Extended runtime config parameters (appended to main or default configuration)
## @param postgresql.replication.enabled Enable replicated postgresql
## @param postgresql.persistence.enabled Enable persistence for PostgreSQL
##
postgresql:
  asSubchart: true
  nameOverride: ""
  host: ""
  port: 5432
  image:
    # registry: docker.io
    repository: bitnami/postgresql
    tag: 14.2.0-debian-10-r58
  ## Name of existing secret to use for PostgreSQL passwords.
  ## If an existingSecret is used it will overwrite postgresqlUsername and postgresqlPassword.
  ## The secret has to contain at least the key postgresql-postgres-password.
  ##
  ## Example Secret:
  ## apiVersion: v1
  ## kind: Secret
  ## metadata:
  ##   name: mysecret
  ## type: Opaque
  ## data:
  ##   postgresqlUsername: YWRtaW4=
  ##   postgresqlPassword: MWYyZDFlMmU2N2Rm
  existingSecret: ""
  ## Authentication parameters
  ## ref: https://github.com/bitnami/bitnami-docker-postgresql/blob/master/README.md#setting-the-root-password-on-first-run
  ## ref: https://github.com/bitnami/bitnami-docker-postgresql/blob/master/README.md#creating-a-database-on-first-run
  ## ref: https://github.com/bitnami/bitnami-docker-postgresql/blob/master/README.md#creating-a-database-user-on-first-run
  ##
  auth:
    ## @param auth.enablePostgresUser Assign a password to the "postgres" admin user. Otherwise, remote access will be blocked for this user
    ##
    enablePostgresUser: true
    ## @param auth.postgresPassword Password for the "postgres" admin user
    ##
    postgresPassword: ""
  postgresqlExtendedConf:
    maxConnections: 1024
  replication:
    enabled: true
  persistence:
    enabled: true
  ## @param postgresql.primary.initdb.scripts [object] Initdb scripts to create databases
  ##
  primary:
    initdb:
      scriptsConfigMap: "gc-psql-init-scripts"

redis:
  # @param redis.asSubchart If external redis is used, set it to `false`
  ##
  asSubchart: true

  hosts: []
  port: ""

  serviceAccount:
    create: true
  ## @param redis.nameOverride String to partially override common.names.fullname template with a string (will prepend the release name)
  ##
  nameOverride: ""
  image:
    # registry: ""
    repository: bitnami/redis
    tag: 6.2.6-debian-10-r179
  auth:
    ## @param redis.auth.enabled Use redis password
    ##
    enabled: true
    ## @param redis.auth.password Redis password
    ## Defaults to a random 10-character alphanumeric string if not set and auth.enabled is true.
    ## It should always be set using the password value or in the existingSecret to avoid issues
    ## with the app.
    ## The password value is ignored if existingSecret is set
    password: ""
  ## @param redis.architecture Cluster settings
  ##
  architecture: replication
  ## Redis&trade; Master parameters
  ## @param redis.master.persistence.enabled Enable persistence for master Redis
  ##
  master:
    replicas: 1
    persistence:
      enabled: true
  ## Redis&trade; Replica parameters
  ## @param redis.replica.persistence.enabled Enable persistence for replica Redis
  ##
  replica:
    replicaCount: 1
    persistence:
      enabled: true

minio:
  asSubchart: true
  ## Provide a name in place of minio for `app:` labels
  ##
  nameOverride: "gc-s3"

  ## Provide a name to substitute for the full names of resources
  ##
  # fullnameOverride: "gc-s3"

  ## set kubernetes cluster domain where minio is running
  ##
  # clusterDomain: lab.internal #cluster.local

  ## Set default image, imageTag, and imagePullPolicy. mode is used to indicate the
  ##
  image:
    repository: quay.io/minio/minio
    tag: RELEASE.2021-12-29T06-49-06Z
    pullPolicy: IfNotPresent

  imagePullSecrets: []
  # - name: "image-pull-secret"

  ## Set default image, imageTag, and imagePullPolicy for the `mc` (the minio
  ## client used to create a default bucket).
  ##
  mcImage:
    repository: quay.io/minio/mc
    tag: RELEASE.2021-12-29T06-52-55Z
    pullPolicy: IfNotPresent

  ## minio mode, i.e. standalone or distributed or gateway.
  mode: standalone #distributed ## other supported values are "standalone", "gateway"

  ## Set default rootUser, rootPassword
  ## AccessKey and secretKey is generated when not set
  ## Distributed MinIO ref: https://docs.minio.io/docs/distributed-minio-quickstart-guide
  ##
  rootUser: ""
  rootPassword: ""

  ## Use existing Secret that store following variables:
  ##
  ## | Chart var             | .data.<key> in Secret    |
  ## |:----------------------|:-------------------------|
  ## | rootUser              | rootUser                 |
  ## | rootPassword          | rootPassword             |
  ##
  ## All mentioned variables will be ignored in values file.
  ## .data.rootUser and .data.rootPassword are mandatory,
  ## others depend on enabled status of corresponding sections.
  existingSecret: ""

  ## Directory on the MinIO pof
  certsPath: "/etc/minio/certs/"
  configPathmc: "/etc/minio/mc/"

  # Number of drives attached to a node
  drivesPerNode: 1
  # Number of MinIO containers running
  replicas: 1
  # Number of expanded MinIO clusters
  pools: 1

  ## TLS Settings for MinIO
  tls:
    enabled: false
    ## Create a secret with private.key and public.crt files and pass that here. Ref: https://github.com/minio/minio/tree/master/docs/tls/kubernetes#2-create-kubernetes-secret
    certSecret: ""
    publicCrt: public.crt
    privateKey: private.key

  ## Trusted Certificates Settings for MinIO. Ref: https://docs.minio.io/docs/how-to-secure-access-to-minio-server-with-tls#install-certificates-from-third-party-cas
  ## Bundle multiple trusted certificates into one secret and pass that here. Ref: https://github.com/minio/minio/tree/master/docs/tls/kubernetes#2-create-kubernetes-secret
  ## When using self-signed certificates, remember to include MinIO's own certificate in the bundle with key public.crt.
  ## If certSecret is left empty and tls is enabled, this chart installs the public certificate from .Values.tls.certSecret.
  trustedCertsSecret: ""

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    enabled: true
    ## minio data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    ## Storage class of PV to bind. By default it looks for standard storage class.
    ## If the PV uses a different storage class, specify that here.
    storageClass: ""
    accessMode: ReadWriteOnce
    size: 100Gi

  ## Configure Ingress based on the documentation here: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ##

  ingress:
    enabled: false
    # ingressClassName: ""
    labels:
      {}
      # node-role.kubernetes.io/ingress: platform
    annotations:
      {}
      # cert-manager.io/cluster-issuer: ""
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      # kubernetes.io/ingress.allow-http: "false"
      # kubernetes.io/ingress.global-static-ip-name: ""
      # nginx.ingress.kubernetes.io/secure-backends: "true"
      # nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      # nginx.ingress.kubernetes.io/whitelist-source-range: 0.0.0.0/0
    path: /
    hosts: []
    tls:
      - secretName: minio-ingress-tls
        hosts: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  consoleService:
    type: ClusterIP
    clusterIP: ~
    ## Make sure to match it to minioConsolePort
    port: "9001"
    nodePort: 32001

  consoleIngress:
    enabled: false
    # ingressClassName: ""
    labels:
      {}
      # node-role.kubernetes.io/ingress: platform

    annotations:
      {}
      # cert-manager.io/cluster-issuer: ""
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      # kubernetes.io/ingress.allow-http: "false"
      # kubernetes.io/ingress.global-static-ip-name: ""
      # nginx.ingress.kubernetes.io/secure-backends: "true"
      # nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      # nginx.ingress.kubernetes.io/whitelist-source-range: 0.0.0.0/0
    path: /
    hosts: []
    tls:
      - secretName: minio-console-ingress-tls
        hosts: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources:
    requests:
      memory: 8Gi

  ## List of policies to be created after minio install
  ##
  ## In addition to default policies [readonly|readwrite|writeonly|consoleAdmin|diagnostics]
  ## you can define additional policies with custom supported actions and resources
  policies: #[]
    ## writeexamplepolicy policy grants creation or deletion of buckets with name
    ## starting with example. In addition, grants objects write permissions on buckets starting with
    ## example.
    - name: gamechangerwrite
      statements:
        - resources:
            - "arn:aws:s3:::advana-data-zone*/*"
          actions:
            - "s3:AbortMultipartUpload"
            - "s3:GetObject"
            - "s3:DeleteObject"
            - "s3:PutObject"
            - "s3:ListMultipartUploadParts"
        - resources:
            - "arn:aws:s3:::advana-data-zone*"
          actions:
            - "s3:CreateBucket"
            - "s3:DeleteBucket"
            - "s3:GetBucketLocation"
            - "s3:ListBucket"
            - "s3:ListBucketMultipartUploads"
    ## readonlyexamplepolicy policy grants access to buckets with name starting with example.
    ## In addition, grants objects read permissions on buckets starting with example.
    - name: gamechangerreadonly
      statements:
        - resources:
            - "arn:aws:s3:::advana-data-zone*/*"
          actions:
            - "s3:GetObject"
        - resources:
            - "arn:aws:s3:::advana-data-zone*"
          actions:
            - "s3:GetBucketLocation"
            - "s3:ListBucket"
            - "s3:ListBucketMultipartUploads"

  ## List of users to be created after minio install
  ##
  users:
    ## Username, password and policy to be assigned to the user
    ## Default policies are [readonly|readwrite|writeonly|consoleAdmin|diagnostics]
    ## Add new policies as explained here https://docs.min.io/docs/minio-multi-user-quickstart-guide.html
    ## NOTE: this will fail if LDAP is enabled in your MinIO deployment
    ## make sure to disable this if you are using LDAP.
    - accessKey: gamechangerreadonly
      secretKey: PLEASE-CHANGE-ME-1
      policy: gamechangerreadonly
    - accessKey: gamechangerwrite
      secretKey: PLEASE-CHANGE-ME-2
      policy: gamechangerwrite
    # Or you can refer to specific secret
    #- accessKey: externalSecret
    #  existingSecret: my-secret
    #  existingSecretKey: password
    #  policy: readonly

  ## List of buckets to be created after minio install
  ##
  buckets:
    - name: advana-data-zone
      policy: none
      versioning: true
    #   # Name of the bucket
    # - name: bucket1
    #   # Policy to be set on the
    #   # bucket [none|download|upload|public]
    #   policy: none
    #   # Purge if bucket exists already
    #   purge: false
    #   # set versioning for
    #   # bucket [true|false]
    #   versioning: false
    # - name: bucket2
    #   policy: none
    #   purge: false
    #   versioning: true

# https://github.com/apache/airflow/tree/main/chart
airflow:
  asSubchart: true
  # Default airflow repository -- overrides all the specific images below
  defaultAirflowRepository: apache/airflow
  airflowVersion: "2.3.0"
  executor: "KubernetesExecutor"

  allowPodLaunching: true

  extraEnvFrom: |
    - configMapRef:
        name: "{{ .Release.Name }}-airflow-crawler-env"

  # Secrets for all airflow containers
  secret:
    - envName: "AIRFLOW_CONN_S3_CONN"
      secretName: "airflow-connections"
      secretKey: "AIRFLOW_CONN_S3_CONN"
  extraSecrets:
    # base64 encoded connection str
    airflow-connections:
      data: |
        "AIRFLOW_CONN_S3_CONN": ""

  # web auth configuration
  webserver:
    # https://airflow.apache.org/docs/apache-airflow/stable/security/webserver.html#example-using-team-based-authorization-with-github-oauth
    extraVolumeMounts:
      - name: webserver-vol
        mountPath: /opt/airflow
        readOnly: true
    extraVolumes:
      - name: webserver-vol
        configMap:
          name: "{{ .Release.Name }}-airflow-webserver-config"
          items:
            - key: webserver_config.py
              path: webserver_config.py

  images:
    airflow:
      repository: ~
      # tag: ~
      pullPolicy: IfNotPresent
    # To avoid images with user code, you can turn this to 'true' and
    # all the 'run-airflow-migrations' and 'wait-for-airflow-migrations' containers/jobs
    # will use the images from 'defaultAirflowRepository:defaultAirflowTag' values
    # to run and wait for DB migrations .
    useDefaultImageForMigration: false
    # timeout (in seconds) for airflow-migrations to complete
    migrationsWaitTimeout: 60
    pod_template:
      repository: ~
      # tag: ~
      pullPolicy: IfNotPresent
    flower:
      repository: ~
      # tag: ~
      pullPolicy: IfNotPresent
    statsd:
      repository: apache/airflow
      tag: airflow-statsd-exporter-2021.04.28-v0.17.0
      pullPolicy: IfNotPresent
    redis:
      repository: redis
      # tag: 6-bullseye
      pullPolicy: IfNotPresent
    pgbouncer:
      repository: apache/airflow
      tag: airflow-pgbouncer-2021.04.28-1.14.0
      pullPolicy: IfNotPresent
    pgbouncerExporter:
      repository: apache/airflow
      # tag: airflow-pgbouncer-exporter-2021.09.22-0.12.0
      pullPolicy: IfNotPresent
    gitSync:
      repository: k8s.gcr.io/git-sync/git-sync
      # tag: v3.4.0
      pullPolicy: IfNotPresent

  postgresql:
    enabled: false
  redis:
    enabled: false
  elasticsearch:
    enabled: false
  flower:
    enabled: false
  webserverSecretKeySecretName: "gc-{{ .Release.Name }}-airflow-webserver"
  fernetKeySecretName: "gc-{{ .Release.Name }}-airflow-fernet"
  data:
    metadataSecretName: "gc-{{ .Release.Name }}-airflow-metadata"
    resultBackendSecretName: "gc-{{ .Release.Name }}-airflow-result"
    brokerUrlSecretName: "gc-{{ .Release.Name }}-airflow-broker"
  logs:
    persistence:
      enabled: true
